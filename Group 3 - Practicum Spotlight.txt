Analyzing Audience Toxicity Across Creator Timelines on YouTube
Exploring Echo Chambers and Evolving Community Behavior

Why This Matters
Toxic discourse is normalized on social platforms, fueled by algorithmic amplification and echo chambers
Content creators regularly harbor hate and harassment in comments, yet there's little longitudinal analysis of their audience behavior
Most toxicity studies focus on platform-wide trends, not individual community evolution

What the Research Tells Us
Echo chambers drive opinion reinforcement and negative emotion within like-minded groups (Del Vicario et al., 2016)
Toxicity drives engagement but reduces monetisation on controversial YouTube channels (Bertaglia et al., 2024)
Highlights how toxic communities can grow despite being less profitable, reinforcing the value of tracking toxicity independently of views or likes.
Hate and harassment cause creators to self-censor or leave platforms, making toxicity more than just an engagement issue (Thomas et al., 2022)
Comment toxicity is underexplored at the creator level over time or by topic

The Gap We’re Addressing
Prior work has focused on:
Platform-wide toxicity (e.g., Twitter, Facebook, Reddit)
Polarization on controversial topics
Creator vulnerability to harassment

Missing piece:
How does toxicity evolve within a single YouTube creator’s audience over time?
Are there consistent patterns or shifts as the channel grows?

Our Research Question
To what extent is audience toxicity consistent across a content creator’s uploads over time, and does it indicate evolving community behavior?
What this lets us explore:
Trends in toxic engagement over time
Shifts in comment culture with audience growth
Links between specific types of videos and toxic responses
Signs of community radicalization or polarization

Project Goals
Track toxicity across all videos on a YouTube channel
Normalize scores to prevent engagement bias
Identify topic-level toxicity
Visualize audience behavior over time
Enable exploration of per-video toxic themes

Project Pipeline
Input: YouTube Channel ID
Data: Video metadata + ~300 top comments/video
User option to sample by relevance or by recency
Scoring: Perspective API for toxicity
Normalization: Adjusted for total comments
Analysis: Topic modeling + optional sentiment
Output: Interactive timeline & detailed video insights

Dashboard Overview
Channel input and sampling method toggle
Time-series graph of toxicity scores
Clickable points show:
Video metadata
Toxicity summary
Per-topic breakdown (BERTopic)
Sample toxic comments
Summary cards (e.g., most toxic video)
Future work if time permits:
LLM summaries of sampled comments
Predicted comment toxicity for next video (ARIMA, Prophet)

Anticipated Insights
Whether toxicity increases with creator fame
If specific topics consistently trigger toxic responses
Whether comment norms shift across eras of a channel
If upload frequency affects audience behavior

Limitations & Assumptions
Only top 300 comments per video analyzed
Perspective API may miss sarcasm or context
Sorting by relevance or recency may bias results
Cannot fully detect bot or coordinated comment campaigns

Sources
Bertaglia, T., Goanta, C., & Iamnitchi, A. (2024). The Monetisation of Toxicity: Analysing
YouTube Content Creators and Controversy-Driven Engagement. , 1-9. https://doi.org/10.1145/3677117.3685005.
Del Vicario, M., Vivaldo, G., Bessi, A., Zollo, F., Scala, A., Caldarelli, G., & Quattrociocchi, W.
(2016). Echo Chambers: Emotional Contagion and Group Polarization on Facebook. Scientific Reports, 6. https://doi.org/10.1038/srep37825.
Thomas, K., Kelley, P., Consolvo, S., Samermit, P., & Bursztein, E. (2022). “It’s common and a
part of being a content creator”: Understanding How Creators Experience and Cope with Hate and Harassment Online. Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3491102.3501879.

